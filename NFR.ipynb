{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Fuzzy Repair (NFR) is a data augmentation pipeline, which integrates fuzzy matches (i.e. similar translations) into neural machine translation.**"
      ],
      "metadata": {
        "id": "jCPd4t2wfRPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/DataAugmentationNMT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzVGbReB4QTB",
        "outputId": "58339a74-1c1f-4686-aac6-29647311342f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/DataAugmentationNMT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For basic usage you can simply install the library via clone from git and pip install.**"
      ],
      "metadata": {
        "id": "zhntM6TRfam2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0KFYVB8p0FL"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/lt3/nfr.git\n",
        "%cd nfr\n",
        "!pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8zmp6eOp8Tm",
        "outputId": "4626980c-84c0-4a0b-b64b-5ee6387d9378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 85.5 MB 93 kB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzM9eR2_qn0p"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **nfr-create-faiss-index:** \n",
        "# Creates a FAISS index for semantic matches with Sent2Vec or Sentence Transformers. This is a necessary step if you want to extract semantic fuzzy matches later on."
      ],
      "metadata": {
        "id": "YWfdZ6Sjfsnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# usage: nfr-create-faiss-index [-h] -c CORPUS_F -p MODEL_NAME_OR_PATH -o\n",
        "                              OUTPUT_F [-m {sent2vec,stransformers}]\n",
        "                              [-b BATCH_SIZE] [--use_cuda]\n",
        "\n",
        "Create a FAISS index based on the semantic representation of an existing text\n",
        "corpus. To do so, the text will be embedded by means of a sent2vec model or a\n",
        "sentence-transformers model. The index is (basically) an efficient list that\n",
        "contains all the representations of the training corpus sentences (the TM). as\n",
        "such, this index can later be used to find those entries that are most similar\n",
        "to a given representation of a sentence. The index is saved to a binary file\n",
        "so that it can be reused later on to calculate cosine similarity scores and to\n",
        "retrieve the most resembling entries.\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help            show this help message and exit\n",
        "  -c CORPUS_F, --corpus_f CORPUS_F\n",
        "                        Path to the corpus to turn into vectors and add to the\n",
        "                        index. This is typically your TM or training file for\n",
        "                        an MT system containing text, one sentence per line\n",
        "  -p MODEL_NAME_OR_PATH, --model_name_or_path MODEL_NAME_OR_PATH\n",
        "                        Path to sent2vec model (when `method` is sent2vec) or\n",
        "                        sentence-transformers model name when method is\n",
        "                        stransformers (see\n",
        "                        https://www.sbert.net/docs/pretrained_models.html)\n",
        "  -o OUTPUT_F, --output_f OUTPUT_F\n",
        "                        Path to the output file to write the FAISS index to\n",
        "  -m {sent2vec,stransformers}, --mode {sent2vec,stransformers}\n",
        "                        Whether to use 'sent2vec' or 'stransformers'\n",
        "                        (sentence-transformers)\n",
        "  -b BATCH_SIZE, --batch_size BATCH_SIZE\n",
        "                        Batch size to use to create sent2vec embeddings or\n",
        "                        sentence-transformers embeddings. A larger value will\n",
        "                        result in faster creation, but may lead to an out-of-\n",
        "                        memory error. If you get such an error, lower the\n",
        "                        value.\n",
        "  --use_cuda            Whether to use GPU when using sentence-transformers.\n",
        "                        Requires PyTorch installation with CUDA support and a\n",
        "                        CUDA-enabled device\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Tq5yXwpDf9_5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2KiV8VFq2rK"
      },
      "outputs": [],
      "source": [
        "!nfr-create-faiss-index  -c /content/gdrive/MyDrive/DataAugmentationNMT/ta/train.en -p paraphrase-multilingual-MiniLM-L12-v2 -o /train.faiss.hi.cln -m stransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEbNMSMksOLi"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **nfr-extract-fuzzy-matches:** \n",
        "# Here, fuzzy matches can be extracted from the training set. A variety of options are available, including semantic fuzzy matching, setsimilarity and edit distance."
      ],
      "metadata": {
        "id": "9YikXoM2gGZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# usage: nfr-extract-fuzzy-matches [-h] --tmsrc TMSRC --tmtgt TMTGT --insrc\n",
        "                                 INSRC --method\n",
        "                                 {editdist,setsim,setsimeditdist,sent2vec,stransformers}\n",
        "                                 --minscore MINSCORE --maxmatch MAXMATCH\n",
        "                                 [--model_name_or_path MODEL_NAME_OR_PATH]\n",
        "                                 [--faiss FAISS] [--threads THREADS]\n",
        "                                 [--n_setsim_candidates N_SETSIM_CANDIDATES]\n",
        "                                 [--setsim_function SETSIM_FUNCTION]\n",
        "                                 [--use_cuda] [-q QUERY_MULTIPLIER]\n",
        "                                 [-v {info,debug}]\n",
        "\n",
        "Given source and target TM files, extract fuzzy matches for a new input file\n",
        "by using a variety of methods. You can use formal matching methods such as\n",
        "edit distance and set similarity, as well as semantic fuzzy matching with\n",
        "sent2vec and Sentence Transformers.\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help            show this help message and exit\n",
        "  --tmsrc TMSRC         Source text of the TM from which fuzzy matches will be\n",
        "                        extracted\n",
        "  --tmtgt TMTGT         Target text of the TM from which fuzzy matches will be\n",
        "                        extracted\n",
        "  --insrc INSRC         Input source file to extract matches for (insrc is\n",
        "                        queried against tmsrc)\n",
        "  --method {editdist,setsim,setsimeditdist,sent2vec,stransformers}\n",
        "                        Method to find fuzzy matches\n",
        "  --minscore MINSCORE   Min fuzzy match score. Only matches with a similarity\n",
        "                        score of at least 'minscore' will be included\n",
        "  --maxmatch MAXMATCH   Max number of fuzzy matches kept per source segment\n",
        "  --model_name_or_path MODEL_NAME_OR_PATH\n",
        "                        Path to sent2vec model (when `method` is sent2vec) or\n",
        "                        sentence-transformers model name when method is\n",
        "                        stransformers (see\n",
        "                        https://www.sbert.net/docs/pretrained_models.html)\n",
        "  --faiss FAISS         Path to faiss index. Must be provided when `method` is\n",
        "                        sent2vec or stransformers\n",
        "  --threads THREADS     Number of threads. Must be 0 or 1 when using\n",
        "                        `use_cuda`\n",
        "  --n_setsim_candidates N_SETSIM_CANDIDATES\n",
        "                        Number of fuzzy match candidates extracted by setsim\n",
        "  --setsim_function SETSIM_FUNCTION\n",
        "                        Similarity function used by setsimsearch\n",
        "  --use_cuda            Whether to use GPU for FAISS indexing and sentence-\n",
        "                        transformers. For this to work properly `threads`\n",
        "                        should be 0 or 1.\n",
        "  -q QUERY_MULTIPLIER, --query_multiplier QUERY_MULTIPLIER\n",
        "                        (applies only to FAISS) Initially look for\n",
        "                        `query_multiplier * maxmatch` matches to ensure that\n",
        "                        we find enough hits after filtering. If still not\n",
        "                        enough matches, search the whole index\n",
        "  -v {info,debug}, --logging_level {info,debug}\n",
        "                        Set the information level of the logger. 'info' shows\n",
        "                        trivial information about the process. 'debug' also\n",
        "                        notifies you when less matches are found than\n",
        "                        requested during semantic matching\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "gvml0iI6gc5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iWktl9w9H11"
      },
      "outputs": [],
      "source": [
        "!nfr-extract-fuzzy-matches --tmsrc /content/gdrive/MyDrive/DataAugmentationNMT/ta/train.en --tmtgt /content/gdrive/MyDrive/DataAugmentationNMT/ta/train.ta --insrc /content/gdrive/MyDrive/DataAugmentationNMT/ta/augmentedOutput.ta.augment.multmax.aug.filtered.1000 --method stransformers --faiss /train.faiss.hi.cln --model_name_or_path  paraphrase-multilingual-MiniLM-L12-v2 --maxmatch 3 --minscore 0.75 --threads 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Slpit the retrieved fuzzy matched source and target sentences .**"
      ],
      "metadata": {
        "id": "EDQyo2mfghhq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOzdLXYNvpa0"
      },
      "outputs": [],
      "source": [
        "import string \n",
        " \n",
        "# Open the file in read mode \n",
        "text = open(\"/content/gdrive/MyDrive/DataAugmentationNMT/ta/augmentedOutput.ta.augment.multmax.aug.filtered.1000.matches.mins0.75.maxm3.stransformers.txt\", \"r\") \n",
        " \n",
        "\n",
        " \n",
        "# Loop through each line of the file \n",
        "for line in text: \n",
        "    # Remove the leading spaces and newline character \n",
        "    line = line.strip() \n",
        " \n",
        "    # Split the line \n",
        "    sentences = line.split(\"\\t\") \n",
        "    with open('eng_ta_0.75.nfr', 'a') as g:\n",
        "         print(sentences[0], file=g)\n",
        "\n",
        "    with open('ta_0.75.nfr', 'a') as g:\n",
        "         print(sentences[3], file=g)\n",
        " \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "nfr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}