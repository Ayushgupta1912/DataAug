{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fast_align&vocab_frq.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtPXmSdnz67M"
      },
      "source": [
        "**fast_align**  to obtain alignments for your bitext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfR7FuaRz1q6"
      },
      "source": [
        "! git clone https://github.com/clab/fast_align\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOfk1f850cwJ"
      },
      "source": [
        "%cd /content/fast_align\n",
        "%mkdir build\n",
        "%cd /content/fast_align/build\n",
        "!cmake ..\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2jVfQgX0sr-"
      },
      "source": [
        "# **Input format**\n",
        "\n",
        "Input to fast_align must be tokenized and aligned into parallel sentences. Each line is a source language sentence and its target language translation, separated by a triple pipe symbol with leading and trailing white space **(|||)**. An example 3-sentence Germanâ€“English parallel corpus is:\n",
        "\n",
        "**doch jetzt ist der Held gefallen . ||| but now the hero has fallen .**\n",
        "\n",
        "**neue Modelle werden erprobt . ||| new models are being tested .**\n",
        "\n",
        "**doch fehlen uns neue Ressourcen . ||| but we lack new resources**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E2rv64E0rV8",
        "outputId": "57ea31fb-bf4d-4073-dfb9-014593b16734"
      },
      "source": [
        "!./fast_align "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: ./fast_align -i file.fr-en\n",
            " Standard options ([USE] = strongly recommended):\n",
            "  -i: [REQ] Input parallel corpus\n",
            "  -v: [USE] Use Dirichlet prior on lexical translation distributions\n",
            "  -d: [USE] Favor alignment points close to the monotonic diagonoal\n",
            "  -o: [USE] Optimize how close to the diagonal alignment points should be\n",
            "  -r: Run alignment in reverse (condition on target and predict source)\n",
            "  -c: Output conditional probability table\n",
            " Advanced options:\n",
            "  -I: number of iterations in EM training (default = 5)\n",
            "  -q: p_null parameter (default = 0.08)\n",
            "  -N: No null word\n",
            "  -a: alpha parameter for optional Dirichlet prior (default = 0.01)\n",
            "  -T: starting lambda for diagonal distance parameter (default = 4)\n",
            "  -s: print alignment scores (alignment ||| score, disabled by default)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPHpq2dC0lO1"
      },
      "source": [
        "!./fast_align -i /content/fast_align/build/bilingual.ta.txt  -d -o -v  > alignment.ta.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMBHSCF22F40"
      },
      "source": [
        "!./fast_align -i /content/fast_align/build/bilingual.ta.txt -d -o -v -p lex.prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z01R0OsN2wfa"
      },
      "source": [
        "To covert logrithimic lexical probability table into lexical probability table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjK68ZR42uQk"
      },
      "source": [
        "import string \n",
        "import math\n",
        "import sys\n",
        " \n",
        "# Open the file in read mode \n",
        "text = open(\"lex.prob\", \"r\") \n",
        "\n",
        "# Loop through each line of the file \n",
        "for line in text: \n",
        "    # Remove the leading spaces and newline character \n",
        "    line = line.strip()\n",
        "    # Split the line into words \n",
        "    words = line.split()\n",
        "    if len(words) >= 3:\n",
        "      prob = words[2] \n",
        "      p= math.exp(float(prob))\n",
        "      p=round(p,5)\n",
        "      words= words[0] + \" \" + words[1] + \" \" + str(p)\n",
        "      line = line.replace(line , words)\n",
        "      with open('lex.ta.txt', 'a') as f:\n",
        "        print(line, file=f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq-3bPsf4HZv",
        "outputId": "f1a9cb14-9c23-436d-a4c5-25d512fe1e0d"
      },
      "source": [
        "%cd /content\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpI2lNWN3r2s"
      },
      "source": [
        "**Generation of vocabulary frequency list**\n",
        "\n",
        "The vocabfreq input is the frequency list of words in the low-resource setting that need augmentation later on using these language models. The format is:\n",
        "\n",
        "...\n",
        "\n",
        "change 3028\n",
        "\n",
        "taken 3007\n",
        "\n",
        "large 2999\n",
        "\n",
        "again 2994\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p36Z9boS2ofl",
        "outputId": "c895393c-03ea-4008-d28c-0f85a9cc67f5"
      },
      "source": [
        "import string \n",
        " \n",
        "# Open the file in read mode \n",
        "text = open(\"/content/sample_data/train.en.ta.cln\", \"r\") \n",
        " \n",
        "# Create an empty dictionary \n",
        "d = dict() \n",
        " \n",
        "# Loop through each line of the file \n",
        "for line in text: \n",
        "    # Remove the leading spaces and newline character \n",
        "    line = line.strip() \n",
        " \n",
        "    # Convert the characters in line to \n",
        "    # lowercase to avoid case mismatch \n",
        "    line = line.lower() \n",
        " \n",
        "    # Remove the punctuation marks from the line  \n",
        " \n",
        "    # Split the line into words \n",
        "    words = line.split(\" \") \n",
        " \n",
        "    # Iterate over each word in line \n",
        "    for word in words: \n",
        "        # Check if the word is already in dictionary \n",
        "        if word in d: \n",
        "            # Increment count of word by 1 \n",
        "            d[word] = d[word] + 1\n",
        "        else: \n",
        "            # Add the word to dictionary with count 1 \n",
        "            d[word] = 1\n",
        "import sys\n",
        "f = open(\"vocab_freq.ta.trg\" , 'w')\n",
        "sys.stdout =f\n",
        "# Print the contents of dictionary \n",
        "for key in sorted(d, key=d.get, reverse=True): \n",
        "  sys.stdout =f\n",
        "  print(key,\" \",d[key],sep=\"\") \n",
        " \n",
        "f.close"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}