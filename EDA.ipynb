{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**We present EDA: easy data augmentation techniques for boosting performance of NMT**\n",
        "\n",
        "Given a sentence in the training set, we perform the following operations:\n",
        "\n",
        "**Synonym Replacement (SR):** Randomly choose n words from the sentence that are not stop words. Replace each of these words with one of its synonyms chosen at random.\n",
        "\n",
        "**Random Insertion (RI**): Find a random synonym of a random word in the sentence that is not a stop word. Insert that synonym into a random position in the sentence. Do this n times.\n",
        "\n",
        "**Random Swap (RS):** Randomly choose two words in the sentence and swap their positions. Do this n times.\n",
        "\n",
        "**Random Deletion (RD):** For each word in the sentence, randomly remove it with probability p"
      ],
      "metadata": {
        "id": "kSoyRNNaCxAG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHVTF71yMM7Z"
      },
      "source": [
        "\n",
        "##**Import Gdrive so output is directy stored in drive***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKGJpNJkW16d",
        "outputId": "d8b92c70-6a82-4b62-eec2-f1eb13d39800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP6qQ1TTYShE",
        "outputId": "e6c6b572-a78d-4343-8af2-cf07ed98ada1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Eda/english_telgu\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/Eda/english_telgu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb5CPlCwMex0"
      },
      "source": [
        "# ##***1. Import the wordnet***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODH_HYv4V49q"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade pyiwn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GVxp4pnY8fv"
      },
      "outputs": [],
      "source": [
        "import pyiwn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HHiAUVbfZll"
      },
      "source": [
        "# ***List of supported languages***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyOYmn0aeW-h",
        "outputId": "f28d24cd-eb92-444e-b8c9-be9e37724400"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Language.ASSAMESE',\n",
              " 'Language.BENGALI',\n",
              " 'Language.BODO',\n",
              " 'Language.GUJARATI',\n",
              " 'Language.HINDI',\n",
              " 'Language.KANNADA',\n",
              " 'Language.KASHMIRI',\n",
              " 'Language.KONKANI',\n",
              " 'Language.MALAYALAM',\n",
              " 'Language.MARATHI',\n",
              " 'Language.MEITEI',\n",
              " 'Language.NEPALI',\n",
              " 'Language.ORIYA',\n",
              " 'Language.PUNJABI',\n",
              " 'Language.SANSKRIT',\n",
              " 'Language.TAMIL',\n",
              " 'Language.TELUGU',\n",
              " 'Language.URDU']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "list(map(str, pyiwn.Language))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NX35prMbZFi3"
      },
      "outputs": [],
      "source": [
        "iwn = pyiwn.IndoWordNet(lang=pyiwn.Language.TELUGU)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID142-SrepoM"
      },
      "source": [
        "# *language defaults to Hindi*\n",
        "\n",
        "to use other language wordnet(s),\n",
        "use:\n",
        "\n",
        "\n",
        "**iwn = pyiwn.IndoWordNet(lang=pyiwn.Language.KANNADA)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp3ruBvVdXLY"
      },
      "source": [
        "# **2. Import stopwords**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwCNYqaHbq54"
      },
      "outputs": [],
      "source": [
        "pip install stopwordsiso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_d1xKm6iVQX"
      },
      "outputs": [],
      "source": [
        "import stopwordsiso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEMAAmcDiVAK"
      },
      "outputs": [],
      "source": [
        "from stopwordsiso import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE6E33nmiUu4"
      },
      "outputs": [],
      "source": [
        "stop_words=list(stopwords(\"hi\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAvtvJ9HMzvK"
      },
      "source": [
        "# ###***FOR SYNNONYM REPLACEMENT***(sr) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xapjdhWbeFs"
      },
      "source": [
        "**Get a list of all the vocabulary present in wordnet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncKfbiD1WMl_"
      },
      "outputs": [],
      "source": [
        "vocab=[]\n",
        "synsets = iwn.all_synsets()\n",
        "for synset in synsets:\n",
        "  for syn in synset.lemma_names():\n",
        "    vocab.append(syn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_DyLJMIWaYK"
      },
      "outputs": [],
      "source": [
        "def get_synonyms(word,n):\n",
        "\tc=[]\n",
        "\tif word in vocab and word not in stop_words:\n",
        "\t\t\ta=iwn.synsets(word)\n",
        "\t\t\tb=a[0]\n",
        "\t\n",
        "\t\t\tc=b.lemma_names()\n",
        "\tx=min(n,len(c)) \n",
        "\treturn list(c[1:x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veNom9yQb7YF"
      },
      "source": [
        "## **FOR A MONOLINGAUL TEXT FILE**\n",
        "\n",
        "# If there is a monolingual file to be augmented we use the code below\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE7hjxnQWmzO"
      },
      "outputs": [],
      "source": [
        "import string \n",
        "import sys\n",
        " \n",
        "# Open the file in read mode \n",
        "text = open(\"/content/gdrive/MyDrive/Eda/aug.tda.hi.txt\", \"r\") \n",
        "f = open(\"aug.tda.hi.sr.txt\" ,'a') \n",
        "for line in text: \n",
        "    # Remove the leading spaces and newline character \n",
        "    line = line.strip() \n",
        "\n",
        " \n",
        " \n",
        "    # Split the line into words \n",
        "    words = line.split(\" \")\n",
        "    for word in words:\n",
        "      synonyms=get_synonyms(word,3)\n",
        "      if(len(synonyms)>0):\n",
        "        \n",
        "        for syn in synonyms:\n",
        "          line2=line.replace(word,syn)\n",
        "          sys.stdout =f\n",
        "          print(line2) \n",
        "f.close\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HADG5JG6cI1R"
      },
      "source": [
        "# **For Bilingual file in fomrat**\n",
        "\n",
        "**English sentence  ||| Hindi sentence**\n",
        "\n",
        "***We use the Hindi/any target language for Augmentation and at the end concatinate both Source and target language in above style ***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzE8upUxZLuz",
        "outputId": "1eb3e983-43b8-4968-983b-8b66b3fb990f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import string \n",
        "import sys\n",
        " \n",
        "# Open the file in read mode \n",
        "text = open(\"/content/gdrive/MyDrive/Eda/english_telgu/tda.eng_te.txt\", \"r\") \n",
        "f = open(\"aug.tda.eng_telugu.sr.txt\" ,'a')\n",
        "\n",
        "for line in text:\n",
        "    parts= line.split(\" ||| \")\n",
        "    eng=parts[0]\n",
        "    hindi=parts[1]\n",
        "  \n",
        "    # Remove the leading spaces and newline character \n",
        "    hin = hindi.strip() \n",
        "    hind=hin\n",
        "\n",
        " \n",
        "\n",
        " \n",
        " \n",
        "    # Split the line into words \n",
        "    words = hin.split(\" \")\n",
        "    for word in words:\n",
        "      synonyms=get_synonyms(word,4)\n",
        "      if(len(synonyms)>0):\n",
        "        for x in range(len(synonyms)):\n",
        "\n",
        "\n",
        "          hin=hin.replace(word,synonyms[x])\n",
        "          sys.stdout =f\n",
        "          print(eng +\" ||| \"+hin)\n",
        "          hin=hind\n",
        "\n",
        "f.close\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9crRLU8ZYllP"
      },
      "source": [
        "# ***RANDOM INSERTION***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zymFFlpyYsUq"
      },
      "outputs": [],
      "source": [
        "def random_insertion(words, n):\n",
        "\tnew_words = words.copy()\n",
        "\tfor _ in range(n):\n",
        "\t\t\n",
        "\t\tadd_word(new_words)\n",
        "\treturn new_words\n",
        "\n",
        "def add_word(new_words):\n",
        "\tsynonyms = []\n",
        "\tcounter = 0\n",
        "\twhile len(synonyms) < 1:\n",
        "\t\trandom_word = new_words[random.randint(0, len(new_words)-1)]\n",
        "\t\tsynonyms = get_synonyms(random_word,2)\n",
        "\t\tcounter += 1\n",
        "\t\tif counter >= 10:\n",
        "\t\t\treturn\n",
        "\trandom_synonym = synonyms[-1]\n",
        "\trandom_idx = random.randint(0, len(new_words)-1)\n",
        "\tnew_words.insert(random_idx, random_synonym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_zZ29uHM63q"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from random import shuffle\n",
        "random.seed(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **FOR A MONOLINGAUL TEXT FILE**"
      ],
      "metadata": {
        "id": "V7bsaWJGGBtF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyAokke0YvHh"
      },
      "outputs": [],
      "source": [
        "import string \n",
        "import sys\n",
        "\n",
        "\n",
        " \n",
        "# Open the file in read mode \n",
        " \n",
        "\n",
        "text= open(\"/content/gdrive/MyDrive/Eda/aug.tda.hi.txt\" ,'r') \n",
        "f = open(\"aug.tda.hi.ri.txt\" ,'a') \n",
        "\n",
        "for line in text: \n",
        "    # Remove the leading spaces and newline character \n",
        "    line = line.strip() \n",
        "    augmented_sentences = []\n",
        "\n",
        " \n",
        " \n",
        " \n",
        "    # Split the line into words \n",
        "    words = line.split(\" \")\n",
        "    a=random_insertion(words,1)\n",
        "    augmented_sentences.append(' '.join(a))\n",
        "    for aug_sentence in augmented_sentences:\n",
        "      sys.stdout =f\n",
        "      print(aug_sentence)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "     \n",
        "f.close"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **For Bilingual file**"
      ],
      "metadata": {
        "id": "asXXiX1VLVa5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0Fg6DV5RZBk",
        "outputId": "564f71ab-844c-415a-9a0d-05fd43247d36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import string \n",
        "import sys\n",
        "\n",
        "\n",
        " \n",
        "# Open the file in read mode \n",
        " \n",
        "\n",
        "text= open(\"/content/gdrive/MyDrive/Eda/eng_tamil/tda.eng_ta.txt\" ,'r') \n",
        "f = open(\"aug.tda.eng_tamil.ri.txt\" ,'a') \n",
        "for line in text:\n",
        "    parts= line.split(\" ||| \")\n",
        "    eng=parts[0]\n",
        "    hindi=parts[1]\n",
        "\n",
        " \n",
        "    # Remove the leading spaces and newline character \n",
        "    hin = hindi.strip() \n",
        "    augmented_sentences = []\n",
        " \n",
        "    # Split the line into words \n",
        "    words = hin.split(\" \")\n",
        "    a=random_insertion(words,1)\n",
        "    augmented_sentences.append(' '.join(a))\n",
        "    for aug_sentence in augmented_sentences:\n",
        "      sys.stdout =f\n",
        "      print(eng+\" ||| \"+aug_sentence)\n",
        "     \n",
        "f.close"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zt3oDhoM7X0"
      },
      "source": [
        "# ###***FOR*** **RAMDOM** **DELETION** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rGg4s9sNyvO"
      },
      "outputs": [],
      "source": [
        "def random_deletion(words, p):\n",
        "\n",
        "\t#obviously, if there's only one word, don't delete it\n",
        "\tif len(words) == 1:\n",
        "\t\treturn words\n",
        "\n",
        "\t#randomly delete words with probability p\n",
        "\tnew_words = []\n",
        "\tfor word in words:\n",
        "\t\tr = random.uniform(0, 1)\n",
        "\t\tif r > p:\n",
        "\t\t\tnew_words.append(word)\n",
        "\n",
        "\t#if you end up deleting all words, just return a random word\n",
        "\tif len(new_words) == 0:\n",
        "\t\trand_int = random.randint(0, len(words)-1)\n",
        "\t\treturn [words[rand_int]]\n",
        "\n",
        "\treturn new_words"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **FOR A MONOLINGAUL TEXT FILE**"
      ],
      "metadata": {
        "id": "GQoiV1WqG5a2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqqjIAh_NE8U",
        "outputId": "4fae34f4-2537-457a-bbaa-5aaf568d6da3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import string \n",
        "import sys\n",
        "\n",
        "\n",
        " \n",
        "# Open the file in read mode \n",
        " \n",
        "\n",
        "text= open(\"/content/gdrive/MyDrive/Eda/aug.tda.hi.txt\" ,'r') \n",
        "f = open(\"aug.tda.hi.rd.txt\" ,'a') \n",
        "\n",
        "for line in text: \n",
        "    # Remove the leading spaces and newline character \n",
        "    line = line.strip() \n",
        "    augmented_sentences = []\n",
        "   \n",
        "   \n",
        "    # Split the line into words \n",
        "    words = line.split(\" \")\n",
        "    a=random_deletion(words,0.2)\n",
        "    augmented_sentences.append(' '.join(a))\n",
        "    for aug_sentence in augmented_sentences:\n",
        "      sys.stdout =f\n",
        "      print(aug_sentence)\n",
        "\n",
        "f.close"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **For Bilingual file**"
      ],
      "metadata": {
        "id": "8R1clS-lHMAz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi3_UAJR70Kp",
        "outputId": "ded4020d-748a-4daf-e584-417e361aff47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "import string \n",
        "import sys\n",
        "\n",
        "\n",
        " \n",
        "# Open the file in read mode \n",
        " \n",
        "\n",
        "text= open(\"/content/gdrive/MyDrive/Eda/eng_tamil/tda.eng_ta.txt\" ,'r') \n",
        "f = open(\"aug.tda.eng_tamil.rd.txt\" ,'a') \n",
        "\n",
        "for line in text:\n",
        "    parts= line.split(\" ||| \")\n",
        "    eng=parts[0]\n",
        "    hindi=parts[1]\n",
        "    hindi = hindi.strip()\n",
        "    \n",
        "    \n",
        "    augmented_sentences = []\n",
        "   \n",
        "   \n",
        "    # Split the line into words \n",
        "    words = hindi.split(\" \")\n",
        "    a=random_deletion(words,0.2)\n",
        "    augmented_sentences.append(' '.join(a))\n",
        "    for aug_sentence in augmented_sentences:\n",
        "      sys.stdout =f\n",
        "      print(eng+\" ||| \"+aug_sentence)\n",
        "\n",
        "f.close"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X09ZB39SsUc"
      },
      "source": [
        "# ***RANDOM SWAP(rs)***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y4OgPRKSrni"
      },
      "outputs": [],
      "source": [
        "def random_swap(words, n):\n",
        "\tnew_words = words.copy()\n",
        "\tfor _ in range(n):\n",
        "\t\tnew_words = swap_word(new_words)\n",
        "\treturn new_words\n",
        "\n",
        "def swap_word(new_words):\n",
        "\trandom_idx_1 = random.randint(0, len(new_words)-1)\n",
        "\trandom_idx_2 = random_idx_1\n",
        "\tcounter = 0\n",
        "\twhile random_idx_2 == random_idx_1:\n",
        "\t\trandom_idx_2 = random.randint(0, len(new_words)-1)\n",
        "\t\tcounter += 1\n",
        "\t\tif counter > 3:\n",
        "\t\t\treturn new_words\n",
        "\tnew_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1] \n",
        "\treturn new_words"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **FOR A MONOLINGAUL TEXT FILE**"
      ],
      "metadata": {
        "id": "l0AGtrvjHBJJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xsQriMlSjkG",
        "outputId": "01f57da6-f7a5-439d-92a3-d918905a0c62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import string \n",
        "import sys\n",
        "\n",
        "\n",
        " \n",
        "# Open the file in read mode \n",
        " \n",
        "\n",
        "text= open(\"/content/gdrive/MyDrive/Eda/aug.tda.hi.txt\" ,'r') \n",
        "f = open(\"aug.tda.hi.rs.txt\" ,'a') \n",
        "\n",
        "for line in text: \n",
        "    # Remove the leading spaces and newline character \n",
        "    line = line.strip() \n",
        "    augmented_sentences = []\n",
        "\n",
        " \n",
        " \n",
        "    # Split the line into words \n",
        "    words = line.split(\" \")\n",
        "    a=random_swap(words,1)\n",
        "    augmented_sentences.append(' '.join(a))\n",
        "    for aug_sentence in augmented_sentences:\n",
        "      sys.stdout =f\n",
        "      print(aug_sentence)\n",
        "\n",
        "f.close"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **For Bilingual file**"
      ],
      "metadata": {
        "id": "ApsArtiVHQVm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OH-siT028qBk"
      },
      "outputs": [],
      "source": [
        "import string \n",
        "import sys\n",
        "\n",
        "\n",
        " \n",
        "# Open the file in read mode \n",
        " \n",
        "\n",
        "text= open(\"/content/gdrive/MyDrive/Eda/eng_tamil/tda.eng_ta.txt\" ,'r') \n",
        "f = open(\"aug.tda.eng_tamil.rs.txt\" ,'a') \n",
        "\n",
        "for line in text:\n",
        "    parts= line.split(\" ||| \")\n",
        "    eng=parts[0]\n",
        "    hindi=parts[1]\n",
        "    hindi = hindi.strip()\n",
        "    augmented_sentences = []\n",
        "\n",
        " \n",
        "\n",
        " \n",
        " \n",
        "    # Split the line into words \n",
        "    words = hindi.split(\" \")\n",
        "    a=random_swap(words,1)\n",
        "    augmented_sentences.append(' '.join(a))\n",
        "    for aug_sentence in augmented_sentences:\n",
        "      sys.stdout =f\n",
        "      print(eng+\" ||| \"+aug_sentence)\n",
        "\n",
        "\n",
        "f.close"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWtu1vFYc5Is"
      },
      "source": [
        "# **To extract Hindi text file from bilingual aug data**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string \n",
        "import sys\n",
        " \n",
        "# Open the file in read mode \n",
        "text = open(\"/content/gdrive/MyDrive/Eda/augmented.bil.txt\", \"r\") \n",
        "\n",
        "h = open(\"hin.aug.txt\" ,'a')\n",
        "\n",
        "for line in text:\n",
        "    parts= line.split(\" ||| \")\n",
        "    eng=parts[0]\n",
        "    hindi=parts[1]\n",
        "    hindi = hindi.strip()\n",
        "\n",
        "    sys.stdout =h\n",
        "    print(hindi)\n",
        "h.close"
      ],
      "metadata": {
        "id": "uh9a5y_0JaML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **To extract english text file from bilingual aug data**"
      ],
      "metadata": {
        "id": "qRr-bawzJhXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string \n",
        "import sys\n",
        " \n",
        "# Open the file in read mode \n",
        "text = open(\"/content/gdrive/MyDrive/Eda/augmented.bil.txt\", \"r\") \n",
        "\n",
        "e = open(\"eng.aug.txt\" ,'a')\n",
        "\n",
        "for line in text:\n",
        "    parts= line.split(\" ||| \")\n",
        "    eng=parts[0]\n",
        "    hindi=parts[1]\n",
        "    eng = eng.strip()\n",
        "\n",
        "    sys.stdout =h\n",
        "    print(eng)\n",
        "e.close"
      ],
      "metadata": {
        "id": "fK4ZbvdUJwyx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EDA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}